{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6b347590-898e-438b-8acf-270559ba54dc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/d/pfournie/dl_toolbox/venv/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import math\n",
    "import torch.nn as nn\n",
    "\n",
    "from torch.utils.data import DataLoader, Subset, RandomSampler, ConcatDataset\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "import torchvision.models as models\n",
    "\n",
    "import dl_toolbox.callbacks as callbacks\n",
    "import dl_toolbox.modules as modules \n",
    "import dl_toolbox.datasets as datasets\n",
    "import dl_toolbox.torch_collate as collate\n",
    "import dl_toolbox.utils as utils\n",
    "import dl_toolbox.torch_sample as sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d20f44f9-10ce-4229-ba2d-87c510ebb8a1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if os.uname().nodename == 'WDTIS890Z': \n",
    "    data_root = Path('/mnt/d/pfournie/Documents/data')\n",
    "    home = Path('/home/pfournie')\n",
    "    save_root = data_root / 'outputs'\n",
    "elif os.uname().nodename == 'qdtis056z': \n",
    "    data_root = Path('/data')\n",
    "    home = Path('/d/pfournie')\n",
    "    save_root = data_root / 'outputs'\n",
    "else:\n",
    "    #data_root = Path('/work/OT/ai4geo/DATA/DATASETS')\n",
    "    data_root = Path(os.environ['TMPDIR'])\n",
    "    home = Path('/home/eh/fournip')\n",
    "    save_root = Path('/work/OT/ai4usr/fournip') / 'outputs'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "45711cf7-300d-4759-96e6-230006ad27fd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# datasets params\n",
    "dataset_name = 'NWPU-RESISC45'\n",
    "data_path = data_root / dataset_name\n",
    "nomenclature = datasets.ResiscNomenclatures['all'].value\n",
    "num_classes=len(nomenclature)\n",
    "\n",
    "train = (0,50)\n",
    "train_idx = [700*i+j for i in range(num_classes) for j in range(*train)]\n",
    "train_aug = 'd4_color-3'\n",
    "\n",
    "val = (600, 700)\n",
    "val_idx = [700*i+j for i in range(num_classes) for j in range(*val)]\n",
    "val_aug = 'no'\n",
    "\n",
    "unsup_train = (50, 100)\n",
    "unsup_idx = [700*i+j for i in range(num_classes) for j in range(*unsup_train)]\n",
    "unsup_aug = 'd4'\n",
    "\n",
    "# dataloaders params\n",
    "batch_size = 16\n",
    "num_workers=6\n",
    "\n",
    "# network params\n",
    "out_channels=num_classes\n",
    "weights = 'IMAGENET1K_V1'\n",
    "\n",
    "# module params\n",
    "mixup=0. # incompatible with ignore_zero=True\n",
    "class_weights = [1.] * num_classes\n",
    "initial_lr=0.001\n",
    "ttas=[]\n",
    "alpha_ramp=utils.SigmoidRamp(2,4,0.,5.)\n",
    "pseudo_threshold=0.9\n",
    "consist_aug='color-5'\n",
    "ema_ramp=utils.SigmoidRamp(2,4,0.9,0.99)\n",
    "\n",
    "# trainer params\n",
    "num_epochs = 5\n",
    "accelerator='gpu'\n",
    "devices=1\n",
    "multiple_trainloader_mode='min_size'\n",
    "limit_train_batches=1.\n",
    "limit_val_batches=1.\n",
    "save_dir = save_root / dataset_name\n",
    "log_name = 'labels:all_nbtran:600'\n",
    "ckpt_path=None # '/data/outputs/test_bce_resisc/version_2/checkpoints/epoch=49-step=14049.ckpt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9c140149-59bd-4e7d-9109-5bd12082f5e3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classes found :  {'airplane': 0, 'bridge': 1, 'commercial_area': 2, 'golf_course': 3, 'island': 4, 'mountain': 5, 'railway_station': 6, 'sea_ice': 7, 'storage_tank': 8, 'airport': 9, 'chaparral': 10, 'dense_residential': 11, 'ground_track_field': 12, 'lake': 13, 'overpass': 14, 'rectangular_farmland': 15, 'ship': 16, 'tennis_court': 17, 'baseball_diamond': 18, 'church': 19, 'desert': 20, 'harbor': 21, 'meadow': 22, 'palace': 23, 'river': 24, 'snowberg': 25, 'terrace': 26, 'basketball_court': 27, 'circular_farmland': 28, 'forest': 29, 'industrial_area': 30, 'medium_residential': 31, 'parking_lot': 32, 'roundabout': 33, 'sparse_residential': 34, 'thermal_power_station': 35, 'beach': 36, 'cloud': 37, 'freeway': 38, 'intersection': 39, 'mobile_home_park': 40, 'railway': 41, 'runway': 42, 'stadium': 43, 'wetland': 44}\n",
      "num samples in dataset :  31500\n",
      "classes found :  {'airplane': 0, 'bridge': 1, 'commercial_area': 2, 'golf_course': 3, 'island': 4, 'mountain': 5, 'railway_station': 6, 'sea_ice': 7, 'storage_tank': 8, 'airport': 9, 'chaparral': 10, 'dense_residential': 11, 'ground_track_field': 12, 'lake': 13, 'overpass': 14, 'rectangular_farmland': 15, 'ship': 16, 'tennis_court': 17, 'baseball_diamond': 18, 'church': 19, 'desert': 20, 'harbor': 21, 'meadow': 22, 'palace': 23, 'river': 24, 'snowberg': 25, 'terrace': 26, 'basketball_court': 27, 'circular_farmland': 28, 'forest': 29, 'industrial_area': 30, 'medium_residential': 31, 'parking_lot': 32, 'roundabout': 33, 'sparse_residential': 34, 'thermal_power_station': 35, 'beach': 36, 'cloud': 37, 'freeway': 38, 'intersection': 39, 'mobile_home_park': 40, 'railway': 41, 'runway': 42, 'stadium': 43, 'wetland': 44}\n",
      "num samples in dataset :  31500\n"
     ]
    }
   ],
   "source": [
    "log_name = f'train={train}_unsup_train={unsup_train}'\n",
    "\n",
    "train_set = Subset(\n",
    "    datasets.Resisc(\n",
    "        data_path=data_path,\n",
    "        img_aug=train_aug,\n",
    "        nomenclature=nomenclature\n",
    "    ),\n",
    "    indices=train_idx\n",
    ")\n",
    "\n",
    "val_set = Subset(\n",
    "    datasets.Resisc(\n",
    "        data_path=data_path,\n",
    "        img_aug=val_aug,\n",
    "        nomenclature=nomenclature\n",
    "    ),\n",
    "    indices=val_idx\n",
    ")   \n",
    "\n",
    "epoch_steps = int(np.ceil(len(train_set) / batch_size))\n",
    "num_train_samples = epoch_steps * batch_size\n",
    "#max_steps=num_epochs * epoch_steps\n",
    "\n",
    "train_dataloaders = {}\n",
    "\n",
    "train_dataloaders['sup'] = DataLoader(\n",
    "    dataset=train_set,\n",
    "    batch_size=batch_size,\n",
    "    collate_fn=collate.CustomCollate(),\n",
    "    sampler=RandomSampler(\n",
    "        data_source=train_set,\n",
    "        replacement=True,\n",
    "        num_samples=num_train_samples\n",
    "    ),\n",
    "    num_workers=num_workers,\n",
    "    pin_memory=True,\n",
    "    drop_last=True\n",
    ")\n",
    "\n",
    "val_dataloader = DataLoader(\n",
    "    dataset=val_set,\n",
    "    shuffle=False,\n",
    "    collate_fn=collate.CustomCollate(),\n",
    "    batch_size=batch_size,\n",
    "    num_workers=num_workers,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ffdb0ec1-60e2-4cab-8024-a86952e96073",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/d/pfournie/dl_toolbox/venv/lib/python3.8/site-packages/pytorch_lightning/utilities/parsing.py:263: UserWarning: Attribute 'network' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['network'])`.\n",
      "  rank_zero_warn(\n"
     ]
    }
   ],
   "source": [
    "network = models.efficientnet_b0(\n",
    "    num_classes=out_channels if weights is None else 1000,\n",
    "    weights=weights\n",
    ")\n",
    "if weights is not None:\n",
    "    # switching head for num_class and init\n",
    "    head = nn.Linear(1280, out_channels) # 1280 comes from 4 * lastconv_input_channels=320 in efficientnet_b0\n",
    "    network.classifier[-1] = head\n",
    "    init_range = 1.0 / math.sqrt(out_channels)\n",
    "    nn.init.uniform_(head.weight, -init_range, init_range)\n",
    "    nn.init.zeros_(head.bias)\n",
    "\n",
    "### Building lightning module\n",
    "module = modules.Supervised(\n",
    "    mixup=mixup, # incompatible with ignore_zero=True\n",
    "    network=network,\n",
    "    #network2=network2,\n",
    "    num_classes=num_classes,\n",
    "    class_weights=class_weights,\n",
    "    initial_lr=initial_lr,\n",
    "    ttas=ttas,\n",
    "    #alpha_ramp=alpha_ramp,\n",
    "    #pseudo_threshold=pseudo_threshold,\n",
    "    #consist_aug=consist_aug,\n",
    "    #ema_ramp=ema_ramp\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "197425e4-052d-49e1-8405-1db7ea9d48ae",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "`Trainer(limit_train_batches=1.0)` was configured so 100% of the batches per epoch will be used..\n",
      "`Trainer(limit_val_batches=1.0)` was configured so 100% of the batches will be used..\n"
     ]
    }
   ],
   "source": [
    "### Metrics and plots from confmat callback\n",
    "metrics_from_confmat = callbacks.MetricsFromConfmat(        \n",
    "    num_classes=num_classes,\n",
    "    class_names=[label.name for label in nomenclature]\n",
    ")\n",
    "\n",
    "### Trainer instance\n",
    "logger = pl.loggers.TensorBoardLogger(\n",
    "    save_dir=save_dir,\n",
    "    name=log_name,\n",
    "    version=f'{datetime.now():%d%b%y-%Hh%Mm%S}'\n",
    ")\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    max_epochs=num_epochs,\n",
    "    accelerator=accelerator,\n",
    "    devices=devices,\n",
    "    multiple_trainloader_mode=multiple_trainloader_mode,\n",
    "    num_sanity_val_steps=0,\n",
    "    limit_train_batches=limit_train_batches,\n",
    "    limit_val_batches=limit_val_batches,\n",
    "    logger=logger,\n",
    "    callbacks=[\n",
    "        pl.callbacks.ModelCheckpoint(),\n",
    "        pl.callbacks.EarlyStopping(\n",
    "            monitor='Val_loss',\n",
    "            patience=10\n",
    "        ),\n",
    "        metrics_from_confmat,\n",
    "        callbacks.MyProgressBar()\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "12982158-dc59-44d4-84c2-54056c5ea6db",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name    | Type             | Params\n",
      "---------------------------------------------\n",
      "0 | network | EfficientNet     | 4.1 M \n",
      "1 | loss    | CrossEntropyLoss | 0     \n",
      "---------------------------------------------\n",
      "4.1 M     Trainable params\n",
      "0         Non-trainable params\n",
      "4.1 M     Total params\n",
      "16.261    Total estimated model params size (MB)\n",
      "/d/pfournie/dl_toolbox/venv/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:488: PossibleUserWarning: Your `val_dataloader`'s sampler has shuffling enabled, it is strongly recommended that you turn shuffling off for val/test/predict dataloaders.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:  82%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                        | 141/173 [00:09<00:02, 14.94it/s, loss=1.11, v_num=0m42]\n",
      "Epoch 0:  87%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                 | 151/173 [00:09<00:01, 15.30it/s, loss=1.11, v_num=0m42]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/d/pfournie/dl_toolbox/venv/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:84: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 16. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n",
      "  warning_cache.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 173/173 [00:10<00:00, 16.78it/s, loss=1.11, v_num=0m42]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/d/pfournie/dl_toolbox/venv/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:84: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 4. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n",
      "  warning_cache.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1:  82%|████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                        | 141/173 [00:08<00:01, 16.79it/s, loss=0.673, v_num=0m42]\n",
      "Epoch 2:  82%|████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                        | 141/173 [00:08<00:01, 16.64it/s, loss=0.625, v_num=0m42]\n",
      "Epoch 3:  82%|████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                        | 141/173 [00:08<00:01, 16.66it/s, loss=0.507, v_num=0m42]\n",
      "Epoch 4:  82%|████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                        | 141/173 [00:08<00:01, 16.63it/s, loss=0.538, v_num=0m42]\n",
      "Epoch 4: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 173/173 [00:12<00:00, 13.92it/s, loss=0.538, v_num=0m42]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=5` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 173/173 [00:12<00:00, 13.60it/s, loss=0.538, v_num=0m42]\n"
     ]
    }
   ],
   "source": [
    "trainer.fit(\n",
    "    model=module,\n",
    "    train_dataloaders=train_dataloaders,\n",
    "    val_dataloaders=val_dataloader,\n",
    "    ckpt_path=ckpt_path\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl_toolbox_venv",
   "language": "python",
   "name": "dl_toolbox_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
