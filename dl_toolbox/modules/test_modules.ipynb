{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "abf3955e-1ebf-4e28-9b2d-74181c44094c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('features', torch.Size([1, 1370, 384]))]\n"
     ]
    }
   ],
   "source": [
    "import timm\n",
    "import torch\n",
    "from torchvision.models.feature_extraction import create_feature_extractor\n",
    "from torchvision.models.feature_extraction import get_graph_node_names\n",
    "\n",
    "model = timm.create_model(\n",
    "    'vit_small_patch14_dinov2',\n",
    "    pretrained=True,\n",
    "    dynamic_img_size=False,\n",
    ")\n",
    "\n",
    "#print(get_graph_node_names(model))\n",
    "encoder = create_feature_extractor(model, {'norm': 'features'})\n",
    "out = encoder(torch.rand(1, 3, 518, 518))\n",
    "print([(k, v.shape) for k, v in out.items()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1cc77b2b-af34-4eec-ab27-f9887f81ec7f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torchvision.transforms.v2 as v2\n",
    "from dl_toolbox import datamodules\n",
    "from pathlib import Path\n",
    "\n",
    "tf = v2.Compose(\n",
    "    [\n",
    "        v2.CenterCrop(280),\n",
    "    ]\n",
    ")\n",
    "  \n",
    "cityscapes = datamodules.Cityscapes(\n",
    "    data_path='/data',\n",
    "    merge='all19',\n",
    "    train_tf=tf,\n",
    "    test_tf=tf,\n",
    "    batch_size=2,\n",
    "    num_workers=0,\n",
    "    pin_memory=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "569ad566-43fa-4f40-bfdf-15e3cd45e9e9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import timm\n",
    "import torch\n",
    "\n",
    "class ViTExtractor:\n",
    "    \"\"\" This class facilitates extraction of features, descriptors, and saliency maps from a ViT.\n",
    "\n",
    "    We use the following notation in the documentation of the module's methods:\n",
    "    B - batch size\n",
    "    h - number of heads. usually takes place of the channel dimension in pytorch's convention BxCxHxW\n",
    "    p - patch size of the ViT. either 8 or 16.\n",
    "    t - number of tokens. equals the number of patches + 1, e.g. HW / p**2 + 1. Where H and W are the height and width\n",
    "    of the input image.\n",
    "    d - the embedding dimension in the ViT.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, model_type='dino_vits8', device='cuda'):\n",
    "        \"\"\"\n",
    "        :param model_type: A string specifying the type of model to extract from.\n",
    "                          [dino_vits8 | dino_vits16 | dino_vitb8 | dino_vitb16 | vit_small_patch8_224 |\n",
    "                          vit_small_patch16_224 | vit_base_patch8_224 | vit_base_patch16_224]\n",
    "        :param stride: stride of first convolution layer. small stride -> higher resolution.\n",
    "        :param model: Optional parameter. The nn.Module to extract from instead of creating a new one in ViTExtractor.\n",
    "                      should be compatible with model_type.\n",
    "        \"\"\"\n",
    "        self.model_type = model_type\n",
    "        self.model = timm.create_model(\n",
    "            model_type,\n",
    "            pretrained=True,\n",
    "            dynamic_img_size=True,\n",
    "        )\n",
    "        self.model_type = model_type\n",
    "        self.device = device\n",
    "        self.model.eval()\n",
    "        self.model.to(self.device)\n",
    "        self.p = self.model.patch_embed.patch_size[0]\n",
    "        self.stride = self.model.patch_embed.proj.stride\n",
    "        self._feats = []\n",
    "        self.hook_handlers = []\n",
    "\n",
    "    def _get_hook(self, facet):\n",
    "        \"\"\"\n",
    "        generate a hook method for a specific block and facet.\n",
    "        \"\"\"\n",
    "        if facet in ['attn', 'token']:\n",
    "            def _hook(model, input, output):\n",
    "                self._feats.append(output)\n",
    "            return _hook\n",
    "\n",
    "        if facet == 'query':\n",
    "            facet_idx = 0\n",
    "        elif facet == 'key':\n",
    "            facet_idx = 1\n",
    "        elif facet == 'value':\n",
    "            facet_idx = 2\n",
    "        else:\n",
    "            raise TypeError(f\"{facet} is not a supported facet.\")\n",
    "\n",
    "        def _inner_hook(module, input, output):\n",
    "            input = input[0]\n",
    "            B, N, C = input.shape\n",
    "            qkv = module.qkv(input).reshape(B, N, 3, module.num_heads, C // module.num_heads).permute(2, 0, 3, 1, 4)\n",
    "            self._feats.append(qkv[facet_idx]) #Bxhxtxd\n",
    "        return _inner_hook\n",
    "\n",
    "    def _register_hooks(self, layers, facet):\n",
    "        \"\"\"\n",
    "        register hook to extract features.\n",
    "        :param layers: layers from which to extract features.\n",
    "        :param facet: facet to extract. One of the following options: ['key' | 'query' | 'value' | 'token' | 'attn']\n",
    "        \"\"\"\n",
    "        for block_idx, block in enumerate(self.model.blocks):\n",
    "            if block_idx in layers:\n",
    "                if facet == 'token':\n",
    "                    self.hook_handlers.append(block.register_forward_hook(self._get_hook(facet)))\n",
    "                elif facet == 'attn':\n",
    "                    self.hook_handlers.append(block.attn.attn_drop.register_forward_hook(self._get_hook(facet)))\n",
    "                elif facet in ['key', 'query', 'value']:\n",
    "                    self.hook_handlers.append(block.attn.register_forward_hook(self._get_hook(facet)))\n",
    "                else:\n",
    "                    raise TypeError(f\"{facet} is not a supported facet.\")\n",
    "\n",
    "    def _unregister_hooks(self) -> None:\n",
    "        \"\"\"\n",
    "        unregisters the hooks. should be called after feature extraction.\n",
    "        \"\"\"\n",
    "        for handle in self.hook_handlers:\n",
    "            handle.remove()\n",
    "        self.hook_handlers = []\n",
    "\n",
    "    def _extract_features(self, batch, layers, facet):\n",
    "        \"\"\"\n",
    "        extract features from the model\n",
    "        :param batch: batch to extract features for. Has shape BxCxHxW.\n",
    "        :param layers: layer to extract. A number between 0 to 11.\n",
    "        :param facet: facet to extract. One of the following options: ['key' | 'query' | 'value' | 'token' | 'attn']\n",
    "        :return : tensor of features.\n",
    "                  if facet is 'key' | 'query' | 'value' has shape Bxhxtxd\n",
    "                  if facet is 'attn' has shape Bxhxtxt\n",
    "                  if facet is 'token' has shape Bxtxd\n",
    "        \"\"\"\n",
    "        B, C, H, W = batch.shape\n",
    "        self._feats = []\n",
    "        self._register_hooks(layers, facet)\n",
    "        _ = self.model(batch)\n",
    "        self._unregister_hooks()\n",
    "        return self._feats\n",
    "\n",
    "    def extract_descriptors(self, batch, layer, facet, bin, include_cls):\n",
    "        \"\"\"\n",
    "        extract descriptors from the model\n",
    "        :param batch: batch to extract descriptors for. Has shape BxCxHxW.\n",
    "        :param layers: layer to extract. A number between 0 to 11.\n",
    "        :param facet: facet to extract. One of the following options: ['key' | 'query' | 'value' | 'token']\n",
    "        :param bin: apply log binning to the descriptor. default is False.\n",
    "        :return: tensor of descriptors. Bx1xtxd' where d' is the dimension of the descriptors.\n",
    "        \"\"\"\n",
    "        assert facet in ['key', 'query', 'value', 'token'], f\"\"\"{facet} is not a supported facet for descriptors. \n",
    "                                                             choose from ['key' | 'query' | 'value' | 'token'] \"\"\"\n",
    "        self._extract_features(batch, [layer], facet)\n",
    "        x = self._feats[0]\n",
    "        if facet == 'token':\n",
    "            x.unsqueeze_(dim=1) #Bx1xtxd\n",
    "        if not include_cls:\n",
    "            x = x[:, :, 1:, :]  # remove cls token\n",
    "        else:\n",
    "            assert not bin, \"bin = True and include_cls = True are not supported together, set one of them False.\"\n",
    "        if not bin:\n",
    "            desc = x.permute(0, 2, 3, 1).flatten(start_dim=-2, end_dim=-1).unsqueeze(dim=1)  # Bx1xtx(dxh)\n",
    "        else:\n",
    "            desc = self._log_bin(x)\n",
    "        return desc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2c10a165-6b4d-401c-ae4f-0651d6f4160c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Descriptors are of size: torch.Size([2, 1, 400, 384])\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "extractor = ViTExtractor('vit_small_patch14_dinov2', device=device)\n",
    "cityscapes.setup(stage='fit')\n",
    "for batch in cityscapes.val_dataloader():\n",
    "    with torch.no_grad():\n",
    "        #image_batch, image_pil = extractor.preprocess(args.image_path, args.load_size)\n",
    "        #print(f\"Image {args.image_path} is preprocessed to tensor of size {image_batch.shape}.\")\n",
    "        descriptors1 = extractor.extract_descriptors(batch['image'].to(device), 11, 'token', bin=False, include_cls=False)\n",
    "        print(f\"Descriptors are of size: {descriptors1.shape}\")\n",
    "        #torch.save(descriptors, args.output_path)\n",
    "        #print(f\"Descriptors saved to: {args.output_path}\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "58be7787-058b-4e75-a8ef-b7df0c2e4aa1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Descriptors are of size: torch.Size([2, 400, 384])\n"
     ]
    }
   ],
   "source": [
    "from dl_toolbox.modules import FeatureExtractor\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "feature_extractor = FeatureExtractor('vit_small_patch14_dinov2', fc_norm=False).to(device)\n",
    "feature_extractor.encoder.prune_intermediate_layers(11,prune_norm=True,prune_head=False)\n",
    "cityscapes.setup(stage='fit')\n",
    "for batch in cityscapes.val_dataloader():\n",
    "    with torch.no_grad():\n",
    "        #image_batch, image_pil = extractor.preprocess(args.image_path, args.load_size)\n",
    "        #print(f\"Image {args.image_path} is preprocessed to tensor of size {image_batch.shape}.\")\n",
    "        descriptors2 = feature_extractor(batch['image'].to(device))[:,1:]\n",
    "        print(f\"Descriptors are of size: {descriptors2.shape}\")\n",
    "        #torch.save(descriptors, args.output_path)\n",
    "        #print(f\"Descriptors saved to: {args.output_path}\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3947c1d7-0332-4e1e-83d2-54f6cf641a96",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.allclose(descriptors1.squeeze(), descriptors2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "96acb85f-3c21-4ecb-b89c-0506353d7567",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/d/pfournie/dl_toolbox/venv/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from functools import partial\n",
    "\n",
    "import torchvision.transforms.v2 as v2\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "from dl_toolbox import datamodules\n",
    "from dl_toolbox import modules\n",
    "from dl_toolbox import networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "51f02842-d1b3-4838-806b-b00c20e8765f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tf = v2.Compose(\n",
    "    [\n",
    "        v2.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ]\n",
    ")\n",
    "\n",
    "datamodule = datamodules.Resisc(\n",
    "    data_path='/data',\n",
    "    train_tf=tf,\n",
    "    test_tf=tf,\n",
    "    merge='all45',\n",
    "    batch_size=16,\n",
    "    num_workers=5,\n",
    "    pin_memory=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "153e167e-0b8b-4d8b-8379-900b5e43f13f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pytorch_lightning as pl\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torchmetrics as M\n",
    "import matplotlib.pyplot as plt\n",
    "from dl_toolbox.utils import plot_confusion_matrix\n",
    "from pytorch_lightning.utilities import rank_zero_info\n",
    "import torch.nn as nn\n",
    "import math\n",
    "from dl_toolbox.transforms import Mixup\n",
    "import timm\n",
    "\n",
    "\n",
    "class Classifier(pl.LightningModule):\n",
    "    def __init__(\n",
    "        self,\n",
    "        encoder,\n",
    "        in_channels,\n",
    "        class_list,\n",
    "        optimizer,\n",
    "        scheduler,\n",
    "        metric_ignore_index,\n",
    "        one_hot,\n",
    "        tta=None,\n",
    "        sliding=None,\n",
    "        *args,\n",
    "        **kwargs\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.class_list = class_list\n",
    "        self.num_classes = len(class_list)\n",
    "        \n",
    "        self.network = timm.create_model(\n",
    "            encoder,\n",
    "            pretrained=True,\n",
    "            num_classes=self.num_classes\n",
    "        )\n",
    "        self.encoder = self.network.blocks\n",
    "        self.loss = torch.nn.CrossEntropyLoss(\n",
    "            ignore_index=-1,\n",
    "            reduction='mean',\n",
    "            weight=None,\n",
    "            label_smoothing=0.\n",
    "        )\n",
    "        self.optimizer = optimizer\n",
    "        self.scheduler = scheduler\n",
    "        \n",
    "        self.tta = tta\n",
    "        self.sliding = sliding\n",
    "        self.one_hot = one_hot\n",
    "        \n",
    "        metric_args = {\n",
    "            'task': 'multiclass',\n",
    "            'num_classes': self.num_classes,\n",
    "            'ignore_index': metric_ignore_index\n",
    "        }\n",
    "        self.val_accuracy = M.Accuracy(**metric_args)\n",
    "        self.test_accuracy = M.Accuracy(**metric_args)\n",
    "        self.val_cm = M.ConfusionMatrix(**metric_args, normalize='true')\n",
    "        self.test_cm = M.ConfusionMatrix(**metric_args, normalize='true')\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        parameters = list(self.parameters())\n",
    "        trainable_parameters = list(filter(lambda p: p.requires_grad, parameters))\n",
    "        rank_zero_info(\n",
    "            f\"The model will start training with only {sum([int(torch.numel(p)) for p in trainable_parameters])} \"\n",
    "            f\"trainable parameters out of {sum([int(torch.numel(p)) for p in parameters])}.\"\n",
    "        )\n",
    "        optimizer = self.optimizer(params=trainable_parameters)\n",
    "        scheduler = self.scheduler(optimizer)\n",
    "        return {\n",
    "            \"optimizer\": optimizer,\n",
    "            \"lr_scheduler\": {\n",
    "                \"scheduler\": scheduler,\n",
    "                \"interval\": \"epoch\"\n",
    "            },\n",
    "        }\n",
    "\n",
    "    def forward(self, x, sliding=None, tta=None):\n",
    "        if sliding is not None:\n",
    "            auxs = [self.forward(aux, tta=tta) for aux in sliding(x)]\n",
    "            return sliding.merge(auxs)\n",
    "        elif tta is not None:\n",
    "            auxs = [self.forward(aux) for aux in tta(x)]\n",
    "            logits = self.forward(x)\n",
    "            return torch.stack([logits] + self.tta.revert(auxs)).sum(dim=0)\n",
    "        else:\n",
    "            return self.network.forward(x)\n",
    "    \n",
    "    def to_one_hot(self, y):\n",
    "        return torch.movedim(F.one_hot(y, self.num_classes),-1,1).float()\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        batch = batch[\"sup\"]\n",
    "        x = batch[\"image\"]\n",
    "        y = batch[\"target\"]\n",
    "        if self.one_hot: y = self.to_one_hot(y)\n",
    "        logits_x = self.forward(x, sliding=None, tta=None)\n",
    "        loss = self.loss(logits_x, y)\n",
    "        self.log(f\"ce/train\", loss)\n",
    "        return loss\n",
    "        \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x = batch[\"image\"]\n",
    "        y = batch[\"target\"]\n",
    "        if self.one_hot: y = self.to_one_hot(y)\n",
    "        logits_x = self.forward(x, sliding=self.sliding)                    \n",
    "        loss = self.loss(logits_x, y)\n",
    "        self.log(f\"ce/val\", loss)\n",
    "        probs = logits_x.softmax(dim=1)\n",
    "        pred_probs, preds = torch.max(probs, dim=1)\n",
    "        self.val_accuracy.update(preds, y)\n",
    "        self.val_cm.update(preds, y)\n",
    "        \n",
    "    def on_validation_epoch_end(self):\n",
    "        val_accuracy = self.val_accuracy.compute()\n",
    "        print(val_accuracy)\n",
    "        self.log(\"accuracy/val\", val_accuracy)\n",
    "        confmat = self.val_cm.compute().detach().cpu()\n",
    "        self.val_accuracy.reset()\n",
    "        self.val_cm.reset()\n",
    "        class_names = [l.name for l in self.class_list]\n",
    "        logger = self.trainer.logger\n",
    "        fs = 12 - 2*(self.num_classes//10)\n",
    "        fig = plot_confusion_matrix(confmat, class_names, norm=None, fontsize=fs)\n",
    "        logger.experiment.add_figure(\"confmat/val\", fig, global_step=self.trainer.global_step)\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        x = batch[\"image\"]\n",
    "        y = batch[\"target\"]\n",
    "        if self.one_hot: y = self.to_one_hot(y)\n",
    "        logits_x = self.forward(x, sliding=self.sliding, tta=self.tta)\n",
    "        loss = self.loss(logits_x, y)\n",
    "        self.log(f\"ce/test\", loss)\n",
    "        probs = logits_x.softmax(dim=1)\n",
    "        pred_probs, preds = torch.max(probs, dim=1)\n",
    "        self.test_accuracy.update(preds, y)\n",
    "        self.test_cm.update(preds, y)\n",
    "        \n",
    "    def on_test_epoch_end(self):\n",
    "        self.log(\"accuracy/test\", self.test_accuracy.compute())\n",
    "        confmat = self.test_cm.compute().detach().cpu()\n",
    "        self.test_accuracy.reset()\n",
    "        self.test_cm.reset()\n",
    "        class_names = [l.name for l in self.class_list]\n",
    "        logger = self.trainer.logger\n",
    "        fs = 12 - 2*(self.num_classes//10)\n",
    "        fig = plot_confusion_matrix(confmat, class_names, norm=None, fontsize=fs)\n",
    "        logger.experiment.add_figure(\"confmat/test\", fig, global_step=self.trainer.global_step)\n",
    "\n",
    "    def predict_step(self, batch, batch_idx):\n",
    "        x = batch[\"image\"]\n",
    "        logits_x = self.forward(x, sliding=self.sliding, tta=self.tta)\n",
    "        return logits_x.softmax(dim=1)\n",
    "    \n",
    "module = Classifier(\n",
    "    encoder='efficientnet_b0',\n",
    "    class_list=datamodule.class_list,\n",
    "    optimizer=partial(torch.optim.SGD, lr=0.01, momentum=0.9, weight_decay=0.0001),\n",
    "    scheduler=partial(torch.optim.lr_scheduler.ConstantLR, factor=1),\n",
    "    in_channels=3,\n",
    "    metric_ignore_index=None,\n",
    "    one_hot=False,\n",
    "    tta=None,\n",
    "    sliding=None,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d40282c-3b82-4088-b853-805c01aa14c4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "`Trainer(limit_train_batches=1.0)` was configured so 100% of the batches per epoch will be used..\n",
      "`Trainer(limit_val_batches=1.0)` was configured so 100% of the batches will be used..\n",
      "Missing logger folder: /d/pfournie/dl_toolbox/dl_toolbox/modules/lightning_logs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "The model will start training with only 510125 trainable parameters out of 4065193.\n",
      "\n",
      "  | Name          | Type                      | Params\n",
      "------------------------------------------------------------\n",
      "0 | network       | EfficientNet              | 4.1 M \n",
      "1 | encoder       | Sequential                | 3.6 M \n",
      "2 | loss          | CrossEntropyLoss          | 0     \n",
      "3 | val_accuracy  | MulticlassAccuracy        | 0     \n",
      "4 | test_accuracy | MulticlassAccuracy        | 0     \n",
      "5 | val_cm        | MulticlassConfusionMatrix | 0     \n",
      "6 | test_cm       | MulticlassConfusionMatrix | 0     \n",
      "------------------------------------------------------------\n",
      "510 K     Trainable params\n",
      "3.6 M     Non-trainable params\n",
      "4.1 M     Total params\n",
      "16.261    Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Checking DataLoader 0:  50%|██████████████████████████████████████████████▌                                              | 1/2 [00:00<00:00,  2.52it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/d/pfournie/dl_toolbox/venv/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:77: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 16. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Checking DataLoader 0: 100%|█████████████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  4.81it/s]tensor(0., device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/d/pfournie/dl_toolbox/venv/lib/python3.8/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: 1035 NaN values found in confusion matrix have been replaced with zeros.\n",
      "  warnings.warn(*args, **kwargs)  # noqa: B028\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████| 1575/1575 [01:39<00:00, 15.84it/s, v_num=0]\n",
      "Validation: |                                                                                                                           | 0/? [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/d/pfournie/dl_toolbox/venv/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:77: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 12. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.8890, device='cuda:0')\n",
      "Epoch 1: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████| 1575/1575 [01:10<00:00, 22.43it/s, v_num=0]\n",
      "Validation: |                                                                                                                           | 0/? [00:00<?, ?it/s]\u001b[Atensor(0.9230, device='cuda:0')\n",
      "Epoch 2: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████| 1575/1575 [01:10<00:00, 22.40it/s, v_num=0]\n",
      "Validation: |                                                                                                                           | 0/? [00:00<?, ?it/s]\u001b[Atensor(0.9259, device='cuda:0')\n",
      "Epoch 3: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████| 1575/1575 [01:10<00:00, 22.38it/s, v_num=0]\n",
      "Validation: |                                                                                                                           | 0/? [00:00<?, ?it/s]\u001b[Atensor(0.9392, device='cuda:0')\n",
      "Epoch 4: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████| 1575/1575 [01:10<00:00, 22.36it/s, v_num=0]\n",
      "Validation: |                                                                                                                           | 0/? [00:00<?, ?it/s]\u001b[Atensor(0.9400, device='cuda:0')\n",
      "Epoch 5: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████| 1575/1575 [01:10<00:00, 22.35it/s, v_num=0]\n",
      "Validation: |                                                                                                                           | 0/? [00:00<?, ?it/s]\u001b[Atensor(0.9421, device='cuda:0')\n",
      "Epoch 6: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████| 1575/1575 [01:10<00:00, 22.36it/s, v_num=0]\n",
      "Validation: |                                                                                                                           | 0/? [00:00<?, ?it/s]\u001b[Atensor(0.9495, device='cuda:0')\n",
      "Epoch 7: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████| 1575/1575 [01:10<00:00, 22.38it/s, v_num=0]\n",
      "Validation: |                                                                                                                           | 0/? [00:00<?, ?it/s]\u001b[Atensor(0.9452, device='cuda:0')\n",
      "Epoch 8: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████| 1575/1575 [01:10<00:00, 22.35it/s, v_num=0]\n",
      "Validation: |                                                                                                                           | 0/? [00:00<?, ?it/s]\u001b[Atensor(0.9483, device='cuda:0')\n",
      "Epoch 9: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████| 1575/1575 [01:10<00:00, 22.37it/s, v_num=0]\n",
      "Validation: |                                                                                                                           | 0/? [00:00<?, ?it/s]\u001b[Atensor(0.9513, device='cuda:0')\n",
      "Epoch 10: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████| 1575/1575 [01:10<00:00, 22.35it/s, v_num=0]\n",
      "Validation: |                                                                                                                           | 0/? [00:00<?, ?it/s]\u001b[Atensor(0.9516, device='cuda:0')\n",
      "Epoch 11: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████| 1575/1575 [01:10<00:00, 22.35it/s, v_num=0]\n",
      "Validation: |                                                                                                                           | 0/? [00:00<?, ?it/s]\u001b[Atensor(0.9535, device='cuda:0')\n",
      "Epoch 12: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████| 1575/1575 [01:10<00:00, 22.36it/s, v_num=0]\n",
      "Validation: |                                                                                                                           | 0/? [00:00<?, ?it/s]\u001b[Atensor(0.9484, device='cuda:0')\n",
      "Epoch 13: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████| 1575/1575 [01:10<00:00, 22.29it/s, v_num=0]\n",
      "Validation: |                                                                                                                           | 0/? [00:00<?, ?it/s]\u001b[Atensor(0.9516, device='cuda:0')\n",
      "Epoch 14: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████| 1575/1575 [01:10<00:00, 22.36it/s, v_num=0]\n",
      "Validation: |                                                                                                                           | 0/? [00:00<?, ?it/s]\u001b[Atensor(0.9530, device='cuda:0')\n",
      "Epoch 15: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████| 1575/1575 [01:10<00:00, 22.38it/s, v_num=0]\n",
      "Validation: |                                                                                                                           | 0/? [00:00<?, ?it/s]\u001b[Atensor(0.9541, device='cuda:0')\n",
      "Epoch 16: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████| 1575/1575 [01:10<00:00, 22.34it/s, v_num=0]\n",
      "Validation: |                                                                                                                           | 0/? [00:00<?, ?it/s]\u001b[Atensor(0.9551, device='cuda:0')\n",
      "Epoch 17: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████| 1575/1575 [01:10<00:00, 22.35it/s, v_num=0]\n",
      "Validation: |                                                                                                                           | 0/? [00:00<?, ?it/s]\u001b[Atensor(0.9556, device='cuda:0')\n",
      "Epoch 18: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████| 1575/1575 [01:10<00:00, 22.35it/s, v_num=0]\n",
      "Validation: |                                                                                                                           | 0/? [00:00<?, ?it/s]\u001b[Atensor(0.9560, device='cuda:0')\n",
      "Epoch 19: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████| 1575/1575 [01:10<00:00, 22.33it/s, v_num=0]\n",
      "Validation: |                                                                                                                           | 0/? [00:00<?, ?it/s]\u001b[Atensor(0.9556, device='cuda:0')\n",
      "Epoch 20: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████| 1575/1575 [01:10<00:00, 22.32it/s, v_num=0]\n",
      "Validation: |                                                                                                                           | 0/? [00:00<?, ?it/s]\u001b[Atensor(0.9556, device='cuda:0')\n",
      "Epoch 21: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████| 1575/1575 [01:10<00:00, 22.36it/s, v_num=0]\n",
      "Validation: |                                                                                                                           | 0/? [00:00<?, ?it/s]\u001b[Atensor(0.9559, device='cuda:0')\n",
      "Epoch 22: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████| 1575/1575 [01:10<00:00, 22.30it/s, v_num=0]\n",
      "Validation: |                                                                                                                           | 0/? [00:00<?, ?it/s]\u001b[Atensor(0.9546, device='cuda:0')\n",
      "Epoch 23: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████| 1575/1575 [01:10<00:00, 22.30it/s, v_num=0]\n",
      "Validation: |                                                                                                                           | 0/? [00:00<?, ?it/s]\u001b[Atensor(0.9567, device='cuda:0')\n",
      "Epoch 24: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████| 1575/1575 [01:10<00:00, 22.35it/s, v_num=0]\n",
      "Validation: |                                                                                                                           | 0/? [00:00<?, ?it/s]\u001b[Atensor(0.9565, device='cuda:0')\n",
      "Epoch 25: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████| 1575/1575 [01:10<00:00, 22.32it/s, v_num=0]\n",
      "Validation: |                                                                                                                           | 0/? [00:00<?, ?it/s]\u001b[Atensor(0.9544, device='cuda:0')\n",
      "Epoch 26: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████| 1575/1575 [01:10<00:00, 22.32it/s, v_num=0]\n",
      "Validation: |                                                                                                                           | 0/? [00:00<?, ?it/s]\u001b[Atensor(0.9576, device='cuda:0')\n",
      "Epoch 27: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████| 1575/1575 [01:10<00:00, 22.35it/s, v_num=0]\n",
      "Validation: |                                                                                                                           | 0/? [00:00<?, ?it/s]\u001b[Atensor(0.9551, device='cuda:0')\n",
      "Epoch 28: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████| 1575/1575 [01:10<00:00, 22.34it/s, v_num=0]\n",
      "Validation: |                                                                                                                           | 0/? [00:00<?, ?it/s]\u001b[Atensor(0.9554, device='cuda:0')\n",
      "Epoch 29: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████| 1575/1575 [01:10<00:00, 22.35it/s, v_num=0]\n",
      "Validation: |                                                                                                                           | 0/? [00:00<?, ?it/s]\u001b[Atensor(0.9565, device='cuda:0')\n",
      "Epoch 30: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████| 1575/1575 [01:10<00:00, 22.37it/s, v_num=0]\n",
      "Validation: |                                                                                                                           | 0/? [00:00<?, ?it/s]\u001b[Atensor(0.9570, device='cuda:0')\n",
      "Epoch 31: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████| 1575/1575 [01:10<00:00, 22.33it/s, v_num=0]\n",
      "Validation: |                                                                                                                           | 0/? [00:00<?, ?it/s]\u001b[Atensor(0.9565, device='cuda:0')\n",
      "Epoch 32: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████| 1575/1575 [01:10<00:00, 22.35it/s, v_num=0]\n",
      "Validation: |                                                                                                                           | 0/? [00:00<?, ?it/s]\u001b[Atensor(0.9576, device='cuda:0')\n",
      "Epoch 33: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████| 1575/1575 [01:10<00:00, 22.32it/s, v_num=0]\n",
      "Validation: |                                                                                                                           | 0/? [00:00<?, ?it/s]\u001b[Atensor(0.9560, device='cuda:0')\n",
      "Epoch 34: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████| 1575/1575 [01:10<00:00, 22.31it/s, v_num=0]\n",
      "Validation: |                                                                                                                           | 0/? [00:00<?, ?it/s]\u001b[Atensor(0.9578, device='cuda:0')\n",
      "Epoch 35: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████| 1575/1575 [01:10<00:00, 22.35it/s, v_num=0]\n",
      "Validation: |                                                                                                                           | 0/? [00:00<?, ?it/s]\u001b[Atensor(0.9556, device='cuda:0')\n",
      "Epoch 36: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████| 1575/1575 [01:10<00:00, 22.33it/s, v_num=0]\n",
      "Validation: |                                                                                                                           | 0/? [00:00<?, ?it/s]\u001b[Atensor(0.9573, device='cuda:0')\n",
      "Epoch 37: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████| 1575/1575 [01:10<00:00, 22.33it/s, v_num=0]\n",
      "Validation: |                                                                                                                           | 0/? [00:00<?, ?it/s]\u001b[Atensor(0.9570, device='cuda:0')\n",
      "Epoch 38: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████| 1575/1575 [01:10<00:00, 22.31it/s, v_num=0]\n",
      "Validation: |                                                                                                                           | 0/? [00:00<?, ?it/s]\u001b[Atensor(0.9563, device='cuda:0')\n",
      "Epoch 39: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████| 1575/1575 [01:10<00:00, 22.36it/s, v_num=0]\n",
      "Validation: |                                                                                                                           | 0/? [00:00<?, ?it/s]\u001b[Atensor(0.9581, device='cuda:0')\n",
      "Epoch 40: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████| 1575/1575 [01:10<00:00, 22.36it/s, v_num=0]\n",
      "Validation: |                                                                                                                           | 0/? [00:00<?, ?it/s]\u001b[Atensor(0.9548, device='cuda:0')\n",
      "Epoch 41: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████| 1575/1575 [01:10<00:00, 22.29it/s, v_num=0]\n",
      "Validation: |                                                                                                                           | 0/? [00:00<?, ?it/s]\u001b[Atensor(0.9567, device='cuda:0')\n",
      "Epoch 42: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████| 1575/1575 [01:10<00:00, 22.34it/s, v_num=0]\n",
      "Validation: |                                                                                                                           | 0/? [00:00<?, ?it/s]\u001b[Atensor(0.9605, device='cuda:0')\n",
      "Epoch 43: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████| 1575/1575 [01:10<00:00, 22.33it/s, v_num=0]\n",
      "Validation: |                                                                                                                           | 0/? [00:00<?, ?it/s]\u001b[A"
     ]
    }
   ],
   "source": [
    "from dl_toolbox.callbacks import ProgressBar, Finetuning, Lora, TiffPredsWriter, CalibrationLogger\n",
    "\n",
    "lora = Lora('encoder', 4, True)\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    accelerator='gpu',\n",
    "    devices=1,\n",
    "    max_steps=100000,\n",
    "    limit_train_batches=1.,\n",
    "    limit_val_batches=1.,\n",
    "    callbacks=[lora, ProgressBar()]\n",
    ")\n",
    "\n",
    "trainer.fit(\n",
    "    module,\n",
    "    datamodule=datamodule,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97106a2d-3343-40f3-975f-ff8f02c34176",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl_toolbox_venv",
   "language": "python",
   "name": "dl_toolbox_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
