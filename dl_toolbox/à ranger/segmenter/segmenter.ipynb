{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "05ce96cb-6b84-4e38-ad3d-0dae195e9f84",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/d/pfournie/dl_toolbox/venv/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import timm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6b61bc75-88a0-4b5b-8f06-03fcc1d8df9d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from einops import rearrange\n",
    "\n",
    "from timm.models.layers import trunc_normal_\n",
    "\n",
    "def init_weights(m):\n",
    "    if isinstance(m, nn.Linear):\n",
    "        trunc_normal_(m.weight, std=0.02)\n",
    "        if isinstance(m, nn.Linear) and m.bias is not None:\n",
    "            nn.init.constant_(m.bias, 0)\n",
    "    elif isinstance(m, nn.LayerNorm):\n",
    "        nn.init.constant_(m.bias, 0)\n",
    "        nn.init.constant_(m.weight, 1.0)\n",
    "\n",
    "class DecoderLinear(nn.Module):\n",
    "    def __init__(self, n_cls, patch_size, d_encoder):\n",
    "        super().__init__()\n",
    "\n",
    "        self.d_encoder = d_encoder\n",
    "        self.patch_size = patch_size\n",
    "        self.n_cls = n_cls\n",
    "\n",
    "        self.head = nn.Linear(self.d_encoder, n_cls)\n",
    "        self.apply(init_weights)\n",
    "\n",
    "    @torch.jit.ignore\n",
    "    def no_weight_decay(self):\n",
    "        return set()\n",
    "\n",
    "    def forward(self, x, im_size):\n",
    "        H, W = im_size\n",
    "        GS = H // self.patch_size\n",
    "        x = self.head(x)\n",
    "        x = rearrange(x, \"b (h w) c -> b c h w\", h=GS)\n",
    "\n",
    "        return x\n",
    "    \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Segmenter(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        encoder,\n",
    "        decoder,\n",
    "        n_cls,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.n_cls = n_cls\n",
    "        self.patch_size = encoder.patch_size\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "\n",
    "    @torch.jit.ignore\n",
    "    def no_weight_decay(self):\n",
    "        def append_prefix_no_weight_decay(prefix, module):\n",
    "            return set(map(lambda x: prefix + x, module.no_weight_decay()))\n",
    "\n",
    "        nwd_params = append_prefix_no_weight_decay(\"encoder.\", self.encoder).union(\n",
    "            append_prefix_no_weight_decay(\"decoder.\", self.decoder)\n",
    "        )\n",
    "        return nwd_params\n",
    "\n",
    "    def forward(self, im):\n",
    "        H_ori, W_ori = im.size(2), im.size(3)\n",
    "        #im = padding(im, self.patch_size)\n",
    "        H, W = im.size(2), im.size(3)\n",
    "\n",
    "        #x = self.encoder(im, return_features=True)\n",
    "        x = self.encoder.forward_features(im)\n",
    "        \n",
    "\n",
    "        # remove CLS/DIST tokens for decoding\n",
    "        #num_extra_tokens = 1 + self.encoder.distilled\n",
    "        #x = x[:, num_extra_tokens:]\n",
    "        x = x[:,self.encoder.num_prefix_tokens:,...]\n",
    "\n",
    "        masks = self.decoder(x, (H, W))\n",
    "\n",
    "        masks = F.interpolate(masks, size=(H, W), mode=\"bilinear\")\n",
    "        #masks = unpadding(masks, (H_ori, W_ori))\n",
    "\n",
    "        return masks\n",
    "\n",
    "#    def get_attention_map_enc(self, im, layer_id):\n",
    "#        return self.encoder.get_attention_map(im, layer_id)\n",
    "#\n",
    "#    def get_attention_map_dec(self, im, layer_id):\n",
    "#        x = self.encoder(im, return_features=True)\n",
    "#\n",
    "#        # remove CLS/DIST tokens for decoding\n",
    "#        num_extra_tokens = 1 + self.encoder.distilled\n",
    "#        x = x[:, num_extra_tokens:]\n",
    "#\n",
    "#        return self.decoder.get_attention_map(x, layer_id)\n",
    "    \n",
    "encoder = timm.create_model('vit_base_patch8_224_dino', pretrained=True)\n",
    "encoder.patch_size = 8\n",
    "decoder = DecoderLinear(n_cls=10, d_encoder=encoder.embed_dim, patch_size=8)\n",
    "model = Segmenter(encoder,decoder,n_cls=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ce71af2a-8867-4e79-ac51-23d7bb195d7a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 10, 224, 224])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.randn(1,3,224,224)\n",
    "model(x).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "891805d5-bbdc-4d48-91d1-c816059d474c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl_toolbox_venv",
   "language": "python",
   "name": "dl_toolbox_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
