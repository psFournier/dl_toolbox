{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "902a3855-9fff-49d7-a550-7bcc359e3961",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "out.keys() = dict_keys(['pred_logits', 'pred_boxes'])\n",
      "[v.shape for v in out.values()] = [torch.Size([2, 100, 11]), torch.Size([2, 100, 4])]\n"
     ]
    }
   ],
   "source": [
    "import timm\n",
    "import torch\n",
    "import torchvision\n",
    "from timm.layers import resample_abs_pos_embed     \n",
    "\n",
    "class Detector(nn.Module):\n",
    "    def __init__(self, num_classes, det_token_num=100):\n",
    "        super().__init__()\n",
    "        self.backbone = timm.create_model('vit_small_patch14_dinov2', pretrained=True, dynamic_img_size=True)\n",
    "        hidden_dim = 384 \n",
    "        self.det_token_num = det_token_num\n",
    "        self.add_det_tokens()\n",
    "        self.class_embed = torchvision.ops.MLP(384, [384,384,num_classes+1])\n",
    "        self.bbox_embed = torchvision.ops.MLP(384, [384,384,4])\n",
    "        \n",
    "    def add_det_tokens(self):\n",
    "        \n",
    "        det_token = nn.Parameter(torch.zeros(1, self.det_token_num, self.backbone.embed_dim))\n",
    "        self.det_token = torch.nn.init.trunc_normal_(det_token, std=.02)\n",
    "        \n",
    "        det_pos_embed = torch.zeros(1, self.det_token_num, self.backbone.embed_dim)\n",
    "        det_pos_embed = torch.nn.init.trunc_normal_(det_pos_embed, std=.02)\n",
    "        cls_pos_embed = self.backbone.pos_embed[:, 0, :][:,None] # size 1x1xembed_dim\n",
    "        patch_pos_embed = self.backbone.pos_embed[:, 1:, :] # 1xnum_patchxembed_dim\n",
    "        self.pos_embed = torch.nn.Parameter(torch.cat((cls_pos_embed, det_pos_embed, patch_pos_embed), dim=1))\n",
    "        \n",
    "        self.backbone.num_prefix_tokens += self.det_token_num\n",
    "        \n",
    "    def _pos_embed_with_det(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        if self.backbone.dynamic_img_size:\n",
    "            B, H, W, C = x.shape\n",
    "            pos_embed = resample_abs_pos_embed(\n",
    "                self.pos_embed,\n",
    "                (H, W),\n",
    "                num_prefix_tokens=0 if self.backbone.no_embed_class else self.backbone.num_prefix_tokens,\n",
    "            )\n",
    "            x = x.view(B, -1, C)\n",
    "        else:\n",
    "            pos_embed = self.pos_embed\n",
    "\n",
    "        to_cat = []\n",
    "        if self.backbone.cls_token is not None:\n",
    "            to_cat.append(self.backbone.cls_token.expand(x.shape[0], -1, -1))\n",
    "        if self.backbone.reg_token is not None:\n",
    "            to_cat.append(self.backbone.reg_token.expand(x.shape[0], -1, -1))\n",
    "        to_cat.append(self.det_token.expand(x.shape[0], -1, -1)) # HERE det tokens\n",
    "\n",
    "        if self.backbone.no_embed_class:\n",
    "            # deit-3, updated JAX (big vision)\n",
    "            # position embedding does not overlap with class token, add then concat\n",
    "            x = x + pos_embed\n",
    "            if to_cat:\n",
    "                x = torch.cat(to_cat + [x], dim=1)\n",
    "        else:\n",
    "            # original timm, JAX, and deit vit impl\n",
    "            # pos_embed has entry for class token, concat then add\n",
    "            if to_cat:\n",
    "                x = torch.cat(to_cat + [x], dim=1)\n",
    "            x = x + pos_embed\n",
    "\n",
    "        return self.backbone.pos_drop(x)\n",
    "        \n",
    "    def backbone_forward_features(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = self.backbone.patch_embed(x)\n",
    "        x = self._pos_embed_with_det(x)\n",
    "        x = self.backbone.patch_drop(x)\n",
    "        x = self.backbone.norm_pre(x)\n",
    "        if self.backbone.grad_checkpointing and not torch.jit.is_scripting():\n",
    "            x = checkpoint_seq(self.backbone.blocks, x)\n",
    "        else:\n",
    "            x = self.backbone.blocks(x)\n",
    "        x = self.backbone.norm(x)\n",
    "        return x\n",
    "    \n",
    "    def forward(self, x):      \n",
    "        x = self.backbone_forward_features(x)\n",
    "        x = x[:,1:1+self.det_token_num,...]\n",
    "        outputs_class = self.class_embed(x)\n",
    "        outputs_coord = self.bbox_embed(x).sigmoid()\n",
    "        out = {'pred_logits': outputs_class, 'pred_boxes': outputs_coord}\n",
    "        return out\n",
    "    \n",
    "detector = Detector(10, 100)\n",
    "x = torch.rand(2, 3, 224, 224)\n",
    "out = detector(x)\n",
    "print(f\"{out.keys() = }\\n{[v.shape for v in out.values()] = }\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f72ef95a-cd19-4778-bbc3-37e3e5f7bd85",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl_toolbox_venv",
   "language": "python",
   "name": "dl_toolbox_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
