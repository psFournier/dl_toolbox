{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10e2fb40-60a9-4c10-83a2-5241b7bb5cf4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import dl_toolbox.datamodules as datamodules\n",
    "import dl_toolbox.transforms as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from dl_toolbox.utils import labels_to_rgb\n",
    "\n",
    "def show_datamodule(dm, batch_type):\n",
    "    dm.prepare_data()\n",
    "    dm.setup(stage='fit')\n",
    "    train_dl = dm.train_dataloader()\n",
    "    for i, batch in enumerate(train_dl):\n",
    "        batch = batch[batch_type]\n",
    "        for j in range(2):\n",
    "            f, ax = plt.subplots(ncols=2, figsize=(20,12))\n",
    "            ax[0].imshow(batch['image'][j].numpy().transpose(1,2,0)[...,:3])\n",
    "            #ax[0].set_title(batch['image_path'][j])\n",
    "            if batch_type=='sup':\n",
    "                ax[1].imshow(labels_to_rgb(batch['label'][j].numpy(),dm.class_colors))\n",
    "                #ax[1].set_title(batch['label_path'][j])\n",
    "        plt.show()  \n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31cdcfec-6a77-4f2b-81d8-f49848f11684",
   "metadata": {
    "tags": []
   },
   "source": [
    "### FLAIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f7bc72d-0016-467e-9f8e-2ffac1b3c75a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2  \n",
    "%matplotlib inline\n",
    "import dl_toolbox.datamodules as datamodules\n",
    "import dl_toolbox.transforms as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from dl_toolbox.utils import labels_to_rgb\n",
    "\n",
    "dm = datamodules.Flair(\n",
    "    #data_path='/work/AI4GEO/users/fournip',\n",
    "    data_path='/data',\n",
    "    #data_path='/scratchm/pfournie/data',\n",
    "    merge='hierarchical6',\n",
    "    sup=3,\n",
    "    unsup=5,\n",
    "    bands=[1,2,3],\n",
    "    dataset_tf=tf.StretchToMinmax([0]*3, [255]*3),\n",
    "    batch_size=2,\n",
    "    num_workers=4,\n",
    "    pin_memory=False\n",
    ")\n",
    "\n",
    "dm.prepare_data()\n",
    "dm.setup(stage='fit')\n",
    "train_dl = dm.train_dataloader()\n",
    "for i, batch in enumerate(train_dl):\n",
    "    batch_type='unsup'\n",
    "    batch = batch[batch_type]\n",
    "    for j in range(2):\n",
    "        f, ax = plt.subplots(ncols=2, figsize=(20,12))\n",
    "        ax[0].imshow(batch['image'][j].numpy().transpose(1,2,0)[...,:3])\n",
    "        #ax[0].set_title(batch['image_path'][j])\n",
    "        if batch_type=='sup':\n",
    "            ax[1].imshow(labels_to_rgb(batch['label'][j].numpy(),dm.class_colors))\n",
    "            #ax[1].set_title(batch['label_path'][j])\n",
    "    plt.show()  \n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3248a7c-bfed-42aa-9bf6-0abfd0b4261f",
   "metadata": {},
   "source": [
    "### PSEUDOSUP FLAIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "098ef9d6-fbb1-433d-ba54-c7ce44056447",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2  \n",
    "\n",
    "from dl_toolbox.datamodules import FlairPseudosup\n",
    "import dl_toolbox.transforms as tf\n",
    "from pathlib import Path\n",
    "import torch\n",
    "\n",
    "pl_dir = Path('/data/outputs/flair2_3_97/supervised_dummy/2023-09-05_102306/checkpoints/last_preds')  \n",
    "\n",
    "dm = FlairPseudosup(\n",
    "    data_path='/data',\n",
    "    merge='hierarchical6',\n",
    "    sup=3,\n",
    "    unsup=0,\n",
    "    bands=[1,2,3],\n",
    "    dataset_tf=tf.StretchToMinmax([0]*3, [255]*3),\n",
    "    batch_size=4,\n",
    "    num_workers=4,\n",
    "    pin_memory=False,\n",
    "    pl_dir=pl_dir,\n",
    "    thresh=10\n",
    ")\n",
    "\n",
    "show_datamodule(dm, 'sup')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a9e3247-7710-49b1-a640-137d2de04681",
   "metadata": {},
   "source": [
    "### Digitanie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c99a8aa6-36f4-4dd5-8cfd-65f4d5150f60",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "1688\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "__call__() missing 1 required positional argument: 'img'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 43\u001b[0m\n\u001b[1;32m     18\u001b[0m dm \u001b[38;5;241m=\u001b[39m datamodules\u001b[38;5;241m.\u001b[39mDigitanie(\n\u001b[1;32m     19\u001b[0m     city\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTOULOUSE\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     20\u001b[0m     data_path\u001b[38;5;241m=\u001b[39mdata,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     40\u001b[0m     pin_memory\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m     41\u001b[0m )\n\u001b[1;32m     42\u001b[0m dm\u001b[38;5;241m.\u001b[39mprepare_data()\n\u001b[0;32m---> 43\u001b[0m \u001b[43mdm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msetup\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mfit\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     44\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mlen\u001b[39m(dm\u001b[38;5;241m.\u001b[39mtrain_s_set))\n\u001b[1;32m     46\u001b[0m dl \u001b[38;5;241m=\u001b[39m dm\u001b[38;5;241m.\u001b[39mtrain_dataloader()\n",
      "File \u001b[0;32m~/dl_toolbox/dl_toolbox/datamodules/digitanie/digitanie.py:66\u001b[0m, in \u001b[0;36mDigitanie.setup\u001b[0;34m(self, stage)\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msetup\u001b[39m(\u001b[38;5;28mself\u001b[39m, stage):\n\u001b[1;32m     62\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_s_set \u001b[38;5;241m=\u001b[39m datasets\u001b[38;5;241m.\u001b[39mDigitanie(\n\u001b[1;32m     63\u001b[0m         \u001b[38;5;241m*\u001b[39m[\u001b[38;5;28mlist\u001b[39m(t) \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_s)],\n\u001b[1;32m     64\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbands,\n\u001b[1;32m     65\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmerge,\n\u001b[0;32m---> 66\u001b[0m         transforms\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_tf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_tf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcity\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     67\u001b[0m     )\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39munsup \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m     69\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_u_set \u001b[38;5;241m=\u001b[39m datasets\u001b[38;5;241m.\u001b[39mDigitanieUnlabeledToa(\n\u001b[1;32m     70\u001b[0m             toa\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtoa,\n\u001b[1;32m     71\u001b[0m             bands\u001b[38;5;241m=\u001b[39m[\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m2\u001b[39m,\u001b[38;5;241m3\u001b[39m],\n\u001b[1;32m     72\u001b[0m             transforms\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_tf(RandomCrop2(\u001b[38;5;241m256\u001b[39m), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcity),\n\u001b[1;32m     73\u001b[0m             windows\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtoa_windows[::\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39munsup]\n\u001b[1;32m     74\u001b[0m         )\n",
      "File \u001b[0;32m~/dl_toolbox/dl_toolbox/datamodules/digitanie/digitanie_ai4geo.py:94\u001b[0m, in \u001b[0;36mDigitanieAi4geo.get_tf\u001b[0;34m(self, tf, city)\u001b[0m\n\u001b[1;32m     92\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m Compose([\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mto_0_1(npy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnpy_stats, city\u001b[38;5;241m=\u001b[39mcity), tf])\n\u001b[1;32m     93\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 94\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m Compose([\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_0_1\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m, tf])\n",
      "\u001b[0;31mTypeError\u001b[0m: __call__() missing 1 required positional argument: 'img'"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2  \n",
    "%matplotlib inline\n",
    "import dl_toolbox.datamodules as datamodules\n",
    "import dl_toolbox.transforms as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from dl_toolbox.utils import labels_to_rgb \n",
    "from functools import partial\n",
    "from pathlib import Path\n",
    "import rasterio\n",
    "\n",
    "data = '/work/AI4GEO/data/DATA/DATASETS'\n",
    "data = '/data'\n",
    "#t = Path(data)/'DIGITANIE_v4/ARCACHON/ARCACHON_20180821_T_16bits_COG.tif'\n",
    "#with rasterio.open(t) as f:\n",
    "#    print(list(f.block_windows())[:10])\n",
    "\n",
    "dm = datamodules.Digitanie(\n",
    "    city='TOULOUSE',\n",
    "    data_path=data,\n",
    "    merge='main5',\n",
    "    bands=[1,2,3],\n",
    "    #dataset_tf=tf.StretchToMinmax([0]*3, [3000]*3),\n",
    "    sup=4,\n",
    "    unsup=1,\n",
    "    #train_tf=partial(\n",
    "    #    tf.NormalizeFromNpy,\n",
    "    #    npy=data+'/DIGITANIE_v4/normalisation_stats.npy',\n",
    "    #    min_p='2',\n",
    "    #    max_p='995',\n",
    "    #    bands=[1,2,3]\n",
    "    #),\n",
    "    to_0_1=tf.To_0_1([0]*3, [3000]*3),\n",
    "    train_tf=tf.NoOp(),\n",
    "    test_tf=tf.NoOp(),\n",
    "    batch_size_s=4,\n",
    "    batch_size_u=4,\n",
    "    steps_per_epoch=250,\n",
    "    num_workers=0,\n",
    "    pin_memory=False\n",
    ")\n",
    "dm.prepare_data()\n",
    "dm.setup(stage='fit')\n",
    "print(len(dm.train_s_set))\n",
    "\n",
    "dl = dm.train_dataloader()\n",
    "for i, batch in enumerate(dl):\n",
    "    batch_type='unsup'\n",
    "    batch = batch[batch_type]\n",
    "    for j in range(2):\n",
    "        f, ax = plt.subplots(ncols=2, figsize=(20,12))\n",
    "        ax[0].imshow(batch['image'][j].numpy().transpose(1,2,0)[...,:3])\n",
    "        #ax[0].set_title(batch['image_path'][j])\n",
    "        if batch_type=='sup':\n",
    "            ax[1].imshow(labels_to_rgb(batch['label'][j].numpy(),dm.class_colors))\n",
    "            #ax[1].set_title(batch['label_path'][j])\n",
    "    plt.show()  \n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7071b1b1-20eb-4b60-96e5-e02b4e03944b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e09ba049-6856-4708-80cc-c865a430d006",
   "metadata": {},
   "source": [
    "### Digi semisup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1556a78-efa3-41a9-a902-ab214ca06735",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2  \n",
    "\n",
    "dm = datamodules.DigitanieCitySemisup(\n",
    "    data_path='/work/AI4GEO/data/DATA/DATASETS',\n",
    "    city='TOULOUSE',\n",
    "    sup=80,\n",
    "    unsup=1,\n",
    "    merge='all9',\n",
    "    bands=[1,2,3],\n",
    "    dataset_tf=tf.StretchToMinmax([0]*3, [8000.]*3),\n",
    "    batch_size=4,\n",
    "    num_workers=0,\n",
    "    pin_memory=False\n",
    ")\n",
    "\n",
    "show_datamodule(dm, 'sup')\n",
    "show_datamodule(dm, 'unsup')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "750fd3fc-d29c-4c82-ada3-6643fea70638",
   "metadata": {},
   "source": [
    "### RESISC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aef5e7e-4b24-4d3d-917a-731a4528d414",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2  \n",
    "%matplotlib inline\n",
    "import dl_toolbox.datamodules as datamodules\n",
    "import dl_toolbox.transforms as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from dl_toolbox.utils import labels_to_rgb\n",
    "import torch.nn.functional as F\n",
    "import dl_toolbox.datasets as datasets\n",
    "\n",
    "transforms = tf.Compose([\n",
    "    #tf.D4(),\n",
    "    tf.RandomCrop2(size=256),\n",
    "    tf.Color([0.6,1.4]),\n",
    "    tf.D4(),\n",
    "    #tf.RandomResizedCrop(size=224, scale=(0.8,1), ratio=(0.8,1.2)),\n",
    "    #tf.StretchToMinmax([0]*3, [255]*3)\n",
    "])\n",
    "\n",
    "dm = datamodules.Resisc(\n",
    "    #data_path='/work/AI4GEO/users/fournip',\n",
    "    #data_path='/scratchm/pfournie/data',\n",
    "    data_path='/data',\n",
    "    merge='all45',\n",
    "    sup=1,\n",
    "    unsup=4,\n",
    "    bands=[1,2,3],\n",
    "    #dataset_tf=tf.StretchToMinmax([0]*3, [255.]*3),\n",
    "    train_tf=transforms,\n",
    "    test_tf=transforms,\n",
    "    batch_size_s=4,\n",
    "    batch_size_u=8,\n",
    "    steps_per_epoch=250,\n",
    "    num_workers=0,\n",
    "    pin_memory=False\n",
    ")\n",
    "\n",
    "dm.prepare_data()\n",
    "dm.setup(stage='fit')\n",
    "dl = dm.train_dataloader()\n",
    "print(len(dm.train_s_set)/45)\n",
    "\n",
    "for i, batch in enumerate(dl):\n",
    "    batch = batch['sup']\n",
    "    xs = batch[\"image\"]\n",
    "    ys = batch[\"label\"]\n",
    "    ys_o = F.one_hot(ys.unsqueeze(1), 45).transpose(1,-1).squeeze(-1).float()\n",
    "    xs, ys_o = tf.Cutmix(0.4)(xs, ys_o)\n",
    "    for j in range(4):\n",
    "        f, ax = plt.subplots(ncols=1, figsize=(6,6))\n",
    "        ax.imshow(xs[j].numpy().transpose(1,2,0))\n",
    "        ax.set_title([(datasets.Resisc.classes['all45'].value[i].name, val) for i,val in enumerate(ys_o[j]) if val!=0])\n",
    "    plt.show()  \n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5ddf3b0-5c59-44dd-9e10-957824257320",
   "metadata": {},
   "source": [
    "### Pseudosup resisc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b42e6843-3871-441a-84eb-2e6382eacd5a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2  \n",
    "\n",
    "from dl_toolbox.datamodules import ResiscPseudosup\n",
    "import dl_toolbox.transforms as tf\n",
    "\n",
    "  \n",
    "dm = ResiscPseudosup(\n",
    "    data_path='/data',\n",
    "    merge='all45',\n",
    "    sup=3,\n",
    "    unsup=0,\n",
    "    dataset_tf=tf.StretchToMinmax([0]*3, [255.]*3),\n",
    "    batch_size=4,\n",
    "    num_workers=4,\n",
    "    pin_memory=False,\n",
    "    pl_dir='/data/outputs/resisc_3_80/sup/2023-09-05_154623/checkpoints/last_preds',\n",
    "    thresh=4000\n",
    ")\n",
    "\n",
    "dm.prepare_data()\n",
    "dm.setup(stage='fit')\n",
    "\n",
    "train_dl = dm.train_dataloader()\n",
    "val_dl = dm.val_dataloader()\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from dl_toolbox.utils import labels_to_rgb\n",
    "\n",
    "for i, batch in enumerate(train_dl):\n",
    "    batch = batch['pseudosup']\n",
    "    for j in range(4):\n",
    "        f, ax = plt.subplots(ncols=1, figsize=(6,6))\n",
    "        ax.imshow(batch['image'][j].numpy().transpose(1,2,0))\n",
    "        ax.set_title(batch['label'][j])\n",
    "    plt.show()  \n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf00b36d-294b-4dae-bacc-dfd6c9ca35f0",
   "metadata": {},
   "source": [
    "### Semcity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2dd9a5c-c020-4659-861e-50b4ec4cd82c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "\n",
    "%autoreload 2  \n",
    "%matplotlib inline\n",
    "import dl_toolbox.datamodules as datamodules\n",
    "import dl_toolbox.transforms as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from dl_toolbox.utils import labels_to_rgb \n",
    "from functools import partial\n",
    "import torch\n",
    "\n",
    "transforms = tf.Compose([\n",
    "    #v2.ToDtype(torch.uint8),  # optional, most input are already uint8 at this point\n",
    "    tf.D4(),\n",
    "    tf.RandomCrop2(size=256),\n",
    "    tf.RandomResizedCrop(size=256, scale=(0.8,1), ratio=(0.8,1.2)),\n",
    "    #tf.StretchToMinmax([0]*3, [255]*3)\n",
    "    tf.Color([0.5,1.5])\n",
    "    #v2.RandomResizedCrop(size=224, scale=(1,1), ratio=(1,1), antialias=True),# Or Resize(antialias=True)\n",
    "    #v2.ToDtype(torch.float32),  # Normalize expects float input\n",
    "    #v2.ColorJitter(hue=0.3),\n",
    "    #v2.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "  \n",
    "dm = datamodules.Semcity(\n",
    "    #data_path='/scratchm/pfournie/data',\n",
    "    #data_path='/work/AI4GEO/users/fournip',\n",
    "    data_path=\"/data\",\n",
    "    merge='main5',\n",
    "    bands=[1,2,3],\n",
    "    sup=1,\n",
    "    unsup=1,\n",
    "    train_tf=transforms,\n",
    "    test_tf=transforms,\n",
    "    #dataset_tf=tf.Compose([\n",
    "    #    tf.Resize([0.5]),\n",
    "    #    tf.RandomCrop2(256),\n",
    "    #    tf.StretchToMinmax([0]*3, [255]*3)\n",
    "    #]),\n",
    "    #dataset_tf=tf.StretchToMinmaxFromCsv(\n",
    "    #    csv='~/dl_toolbox/dl_toolbox/datasets/semcity/semcity_stats.csv',\n",
    "    #    min_p='p0.0',\n",
    "    #    max_p='p99.0',\n",
    "    #    bands=[1,2,3]\n",
    "    #),\n",
    "    batch_size_s=4,\n",
    "    batch_size_u=8,\n",
    "    steps_per_epoch=250,\n",
    "    num_workers=0,\n",
    "    pin_memory=False\n",
    ")\n",
    "\n",
    "dm.prepare_data()\n",
    "dm.setup(stage='fit')\n",
    "train_dl = dm.train_dataloader()\n",
    "for i, batch in enumerate(train_dl):\n",
    "    batch_type='sup'\n",
    "    batch = batch[batch_type]\n",
    "    for j in range(4):\n",
    "        f, ax = plt.subplots(ncols=2, figsize=(20,12))\n",
    "        ax[0].imshow(batch['image'][j].numpy().transpose(1,2,0)[...,:3])\n",
    "        #ax[0].set_title(batch['image_path'][j])\n",
    "        if batch_type=='sup':\n",
    "            ax[1].imshow(labels_to_rgb(batch['label'][j].numpy(),dm.class_colors))\n",
    "            #ax[1].set_title(batch['label_path'][j])\n",
    "    plt.show()  \n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a28ece46-ae00-4d7a-b94d-753dfcd15c3f",
   "metadata": {},
   "source": [
    "### Semcity Pseudosup not implemented"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a39ac761-f74b-4264-ab55-232b17049763",
   "metadata": {},
   "source": [
    "### AIRS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4adc2b0-12bb-427e-b60d-f2c026e953b9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2  \n",
    "\n",
    "from dl_toolbox.datamodules import Airs\n",
    "import dl_toolbox.transforms as tf\n",
    "\n",
    "  \n",
    "dm = Airs(\n",
    "    data_path='/work/AI4GEO/data/DATA/DATASETS',\n",
    "    filter_path='/work/AI4GEO/users/fournip/AIRS/train.csv',\n",
    "    merge='building',\n",
    "    bands=[1,2,3],\n",
    "    sup=3,\n",
    "    unsup=5,\n",
    "    dataset_tf=tf.StretchToMinmax([0]*3, [255.]*3),\n",
    "    batch_size=4,\n",
    "    num_workers=0,\n",
    "    pin_memory=False\n",
    ")\n",
    "\n",
    "show_datamodule(dm, 'unsup')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f81a83e0-6bd0-428a-bb82-bde9ac16a3f7",
   "metadata": {},
   "source": [
    "### CITYSCAPES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e438fbae-de00-46fe-b378-8d4572228c7e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2  \n",
    "%matplotlib inline\n",
    "import dl_toolbox.datamodules as datamodules\n",
    "import dl_toolbox.transforms as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from dl_toolbox.utils import labels_to_rgb\n",
    "from dl_toolbox.datamodules import Cityscapes\n",
    "import dl_toolbox.transforms as tf\n",
    "\n",
    "  \n",
    "dm = Cityscapes(\n",
    "    data_path='/data',\n",
    "    merge='all19',\n",
    "    sup=3,\n",
    "    unsup=5,\n",
    "    dataset_tf=tf.NoOp(),\n",
    "    batch_size=2,\n",
    "    num_workers=0,\n",
    "    pin_memory=False\n",
    ")\n",
    "\n",
    "dm.prepare_data()\n",
    "dm.setup(stage='fit')\n",
    "\n",
    "train_dl = dm.train_dataloader()\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from dl_toolbox.utils import labels_to_rgb\n",
    "\n",
    "for i, batch in enumerate(train_dl):\n",
    "    batch = batch['sup']\n",
    "    for j in range(2):\n",
    "        f, ax = plt.subplots(ncols=2, figsize=(20,12))\n",
    "        ax[0].imshow(batch['image'][j].numpy().transpose(1,2,0)[...,:3])\n",
    "        ax[1].imshow(labels_to_rgb(batch['label'][j].numpy(),dm.class_colors))\n",
    "        for l in range(2):\n",
    "            ax[l].set(xticklabels=[], yticklabels=[], xticks=[], yticks=[])\n",
    "    plt.show()  \n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d6f6b41-c980-4129-a200-a9c2a0b06954",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl_toolbox_venv",
   "language": "python",
   "name": "dl_toolbox_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
