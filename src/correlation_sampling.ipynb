{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "749aa0c2-4b68-4c91-8675-7f4ecf793c21",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import argparse\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from spatial_correlation_sampler import SpatialCorrelationSampler\n",
    "\n",
    "\n",
    "def check_equal(first, second, verbose):\n",
    "    if verbose:\n",
    "        print()\n",
    "    for i, (x, y) in enumerate(zip(first, second)):\n",
    "        x = x.cpu().detach().numpy()\n",
    "        y = y.cpu().detach().numpy()\n",
    "        if verbose:\n",
    "            print(\"x = {}\".format(x.flatten()))\n",
    "            print(\"y = {}\".format(y.flatten()))\n",
    "            print('-' * 80)\n",
    "        np.testing.assert_allclose(x, y, err_msg=\"Index: {}\".format(i))\n",
    "\n",
    "\n",
    "def zero_grad(variables):\n",
    "    for variable in variables:\n",
    "        if variable.grad is not None: variable.grad.zero_()\n",
    "\n",
    "\n",
    "def get_grads(variables):\n",
    "    return [var.grad.clone() for var in variables]\n",
    "\n",
    "\n",
    "def check_forward(input1, input2, correlation_sampler, verbose, gpu_index=0):\n",
    "    device = torch.device(f\"cuda:{gpu_index}\")\n",
    "\n",
    "    cpu_values = correlation_sampler(input1, input2)\n",
    "    cuda_values = correlation_sampler(input1.to(device), input2.to(device))\n",
    "\n",
    "    print(f\"Forward: CPU vs. CUDA device:{gpu_index} ... \", end='')\n",
    "    check_equal(cpu_values, cuda_values, verbose)\n",
    "    print('Ok')\n",
    "\n",
    "\n",
    "def check_backward(input1, input2, correlation_sampler, verbose, gpu_index=0):\n",
    "    device = torch.device(f\"cuda:{gpu_index}\")\n",
    "\n",
    "    zero_grad([input1, input2])\n",
    "\n",
    "    cpu_values = correlation_sampler(input1, input2)\n",
    "    cpu_values.sum().backward()\n",
    "    grad_cpu = get_grads([input1, input2])\n",
    "\n",
    "    zero_grad([input1, input2])\n",
    "\n",
    "    cuda_values = correlation_sampler(input1.to(device), input2.to(device))\n",
    "    cuda_values.sum().backward()\n",
    "    grad_cuda = get_grads([input1, input2])\n",
    "\n",
    "    print(f\"Backward: CPU vs. CUDA device:{gpu_index} ... \", end='')\n",
    "    check_equal(grad_cpu, grad_cuda, verbose)\n",
    "    print('Ok')\n",
    "\n",
    "\n",
    "def check_multi_gpu_forward(correlation_sampler, verbose):\n",
    "    print(\"Multi-GPU forward\")\n",
    "    total_gpus = torch.cuda.device_count()\n",
    "    for gpu in range(total_gpus):\n",
    "        check_forward(input1, input2, correlation_sampler, verbose, gpu_index=gpu)\n",
    "\n",
    "def check_multi_gpu_backward(correlation_sampler, verbose):\n",
    "    print(\"Multi-GPU backward\")\n",
    "    total_gpus = torch.cuda.device_count()\n",
    "    for gpu in range(total_gpus):\n",
    "        check_backward(input1, input2, correlation_sampler, verbose, gpu_index=gpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b5ef044-246f-43bb-91b6-0c9338f4d84b",
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('direction', choices=['forward', 'backward'], nargs='+')\n",
    "parser.add_argument('-b', '--batch-size', type=int, default=1)\n",
    "parser.add_argument('-k', '--kernel-size', type=int, default=3)\n",
    "parser.add_argument('--patch', type=int, default=3)\n",
    "parser.add_argument('--patch_dilation', type=int, default=2)\n",
    "parser.add_argument('-c', '--channel', type=int, default=10)\n",
    "parser.add_argument('--height', type=int, default=10)\n",
    "parser.add_argument('-w', '--width', type=int, default=10)\n",
    "parser.add_argument('-s', '--stride', type=int, default=2)\n",
    "parser.add_argument('-p', '--pad', type=int, default=5)\n",
    "parser.add_argument('-v', '--verbose', action='store_true', default=False)\n",
    "parser.add_argument('-d', '--dilation', type=int, default=2)\n",
    "args = parser.parse_args()\n",
    "print(args)\n",
    "\n",
    "assert(torch.cuda.is_available()), \"no comparison to make\"\n",
    "input1 = torch.randn(args.batch_size,\n",
    "                     args.channel,\n",
    "                     args.height,\n",
    "                     args.width).double()\n",
    "input2 = torch.randn(args.batch_size,\n",
    "                     args.channel,\n",
    "                     args.height,\n",
    "                     args.width).double()\n",
    "input1.requires_grad = True\n",
    "input2.requires_grad = True\n",
    "\n",
    "correlation_sampler = SpatialCorrelationSampler(\n",
    "    args.kernel_size,\n",
    "    args.patch,\n",
    "    args.stride,\n",
    "    args.pad,\n",
    "    args.dilation,\n",
    "    args.patch_dilation)\n",
    "\n",
    "if 'forward' in args.direction:\n",
    "    check_forward(input1, input2, correlation_sampler, args.verbose)\n",
    "    if torch.cuda.device_count() > 1: check_multi_gpu_forward(correlation_sampler, args.verbose)\n",
    "\n",
    "if 'backward' in args.direction:\n",
    "    check_backward(input1, input2, correlation_sampler, args.verbose)\n",
    "    if torch.cuda.device_count() > 1: check_multi_gpu_backward(correlation_sampler, args.verbose)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl_toolbox_38",
   "language": "python",
   "name": "dl_toolbox_38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
